---
title: AI Literacy in Higher Education
subtitle: Transforming Teaching and Learning in Modern Education
lead: AI technologies are revolutionizing higher education, providing new approaches to personalized learning while raising important ethical considerations.
description: An overview of AI's impact on higher education institutions, examining personalized learning, intelligent tutoring, data-driven insights, and ethical considerations.

date: 2025-06-26T10:00:00Z
authors:
- bogdan
tags:
  - AI in Education
  - Higher Education
  - Teaching with AI
  - AI Ethics
  - AI Literacy
categories:
  - Project Updates
slug:

resources:
  - src: images/ai-literacy.jpeg
    name: "header"
layout: single 
copyright:
  name: AI-HED Project
  href: https://ai-hed.eu/

options:
  header:
  headerHeight: 100
  headerSubtitleColor:
  headerTitleColor:
  hideFooter: false
  hideSubscribeForm: false
  showHeader: true
  ShowHeaderSubscribeForm: false
  unlisted: false

draft: false
disable_comments: true
---

Many aspects of modern life are under the influence and being revolutionised by the use or the presence of artificial intelligence (AI). Even though it was once considered and perceived to be simply a concept from futuristic tales, AI profoundly influences our lives in modern times, including our daily interactions, decisions, and behaviour. From personalised digital assistants such as Siri and Alexa, over the backend, serving us customised recommendations while shopping, to complex systems diagnosing various illnesses, AI technologies significantly impact the modern civilisation. The rapid advancements we have experienced recently show promise of a continual transformation in multiple disciplines across the globe, including industry, society, and education.

One of the crucial roles higher education institutions (HEIs) play in the modern society is integrating, researching, and developing many different facets of AI. They serve as state-of-the-art research hubs that combine theory with practical applications. Universities worldwide use AI to streamline administrative processes, foster innovation, improve educational outcomes, and enhance teaching and learning processes. Therefore, integrating AI into education impacts technological advancement, substantial pedagogical changes and challenges, and strategic institutional development.

## The AI-HED Project: Fostering AI Integration in Higher Education

The Erasmus+ Cooperation Partnership project, titled Artificial Intelligence in Higher Education Teaching and Learning (AI-HED), acknowledges the importance of this strategic integration. With international collaboration between Stichting Hogeschool van Amsterdam, Fachhochschule des BFI Wien, Instituto Politécnico de Lisboa, and the University of Zagreb Faculty of Organization and Informatics, the AI-HED project's objective is to empower HEIs to foster and utilise the potential of AI technologies in teaching and learning processes. The project's essential objective is enhancing the digital competencies of educators and students and fostering enriched interactive educational experiences.

## Key Areas of AI Application in Higher Education

The application of AI in higher education can be observed as both extensive and diversified, thus offering modern and innovative approaches to teaching and learning processes. More than simply adaptive learning systems or intelligent tutoring platforms, AI can be seen in HEIs in roles that could be classified in the following key areas.

### Personalised Learning

Various AI-based models, tools, and systems make creating a personalised learning experience for students and learners of various profiles and features easier. Furthermore, individualised and customised approaches can be realised due to the possibilities of analysing learners' performance, learning styles, and preferences. Therefore, it is possible to customise content delivery to best suit individual learners and their unique needs and preferences. 

An AI-powered system might suggest specific learning sources to students based on their perceived or defined preferences, or it may adjust the difficulty level of particular assignments regarding the specific student's record, thus helping create a more engaging and effective learning environment. This level of personalisation may induce better student engagement and improve retention and academic outcomes.

### Intelligent Tutoring

These systems may be used or implemented as simulations of individual interaction with a human tutor to provide students with real-time or immediate and personalised feedback and guidance on further learning. Such a system might offer targeted explanations, hints, or additional learning resources based on the student's perceived understanding of a given topic. 

The student's level of knowledge may be determined by using quizzes, simple conversations, or different types of assignments. The personalised learning experience is tightly tied to and is one of the significant points of intelligent tutoring systems.

### Automated Assessment and Feedback

AI may facilitate the automation of grading and feedback processes, especially for assessment instances that can be graded objectively or feature multiple-choice or true/false questions. Some more advanced AI-based tools and systems may be used to analyse the content, structure, and coherence of more advanced and unstructured types of content, such as open-ended responses and essays. 

Such an automation opportunity should not wholly be used to automate the assessment and feedback processes. Instead, it should be used as an aide for teachers.

### Virtual Teaching

AI-based virtual assistants can be implemented and integrated into higher education as instructors or students. As instructors, they can be helpful to students who can have a personalised tutor available at any given moment. As students, these systems may be used to test and verify learning materials, gauge the difficulty levels of assignments, or assess the cohesiveness and consistency of the prepared contents. 

Furthermore, such systems may be used to handle routine inquiries, explain the course material's content, and facilitate discussions.

### Data-Driven Insights

While personalised learning and intelligent tutoring systems face users, i.e. the learners, the other side of such systems may provide teachers and education institutions with valuable data. Such data may contain insights into student performance, engagement levels, and possibly behaviour that may lead students to a risky situation education-wise. 

Patterns and trends hidden in these data may be priceless in leading teachers to make the best decisions about instructional strategies, curriculum design, and personal interventions to help students succeed. Eventually, acting on the insights provided by data analysis may give educators the necessary edge to assume a proactive role in education and address educational challenges rather than a reactive one.

### Collaborative Learning

It may be easier to form student groups using AI-based tools and systems in a way that would optimise peer interaction based on the complementary skills and learning styles of students. Furthermore, coupling this aspect of using AI in HEIs with personalised learning or intelligent tutoring may provide a collaborative environment that encourages inquiry-based learning and promotes critical thinking, all while fostering collaborative problem-solving skills.

### Administrative Tasks

Even though it is most interesting to observe and consider the use of AI-based models, tools, and systems within the constraints of student-teacher interaction, these tools may also be used in streamlining and automating administrative tasks. Enrolment management, scheduling, and resource allocation are only some of the challenges already researched as application domains of AI.

## Environmental Considerations

Some of the above-mentioned areas and examples of using AI in higher education have the prospect of thoroughly changing the current approach to education. Running these systems, though, usually demands constant connection to the Internet and entails a non-trivial demand towards the electricity grid. Moreover, the computational intensity and significant energy consumption associated with AI-based tools and systems contribute significantly to global electric energy consumption. Hence, using and developing such tools is critical in global environmental concerns.

Even though the end-user might not perceive the amount of energy required for a 'simple' task given to an AI-based tool or system, especially in the context of using modern large language model (LLM) agents such as Le Chat, the actual figures should not be ignored. Increased reliance on various AI-based tools and systems should be thought through in the context of environmental implications before making the final decision. Although some of the most well-known names in the domain of publicly available LLM agents already started increasing their investments in the energy industry, the problem of a sharp increase in electric energy consumption in recent years should not be ignored in the discussions on using AI-based tools and systems.

Ultimately, HEIs should observe AI adoption as complementary to human intelligence, skills, and abilities rather than replacing them. Should AI-based tools and systems be considered educator empowerment, creative, critical, and personalised mentoring may enable new teaching and learning approaches that foster student engagement.

## Ethical and Privacy Considerations

Many AI-based tools and systems have become widely and publicly available due to some of the most recent advancements in the domain of artificial intelligence and related research. These tools base their output on massive amounts of data collected for training the AI models in the backend. Such models are very often enriched by the conversations users have with the prepared interface to the chosen models. This approach to using AI models is beneficial in terms of ease of use and accessibility, but is a cause of concern and vigilance in the context of ethics and privacy.

### The Turing Test Milestone

Some of the most recent academic and professional advancements in the domain of AI made it possible for anybody with the connection to the Internet to interact with various types of AI models, most notably various types of language models (LLMs, e.g. Le Chat), including small, large, and multimodal. State-of-the-art studies claim that at least one such model passed the legendary Turing test. Turing test was designed by Alan Turing in 1950 as a way to test whether machines could exhibit human-like intelligence. 

The test involves a human evaluator who engages in a natural language conversation with both a human and a machine, trying to determine which is which. If the evaluator cannot reliably distinguish the machine from the human, the machine is said to have passed the Turing test. It is claimed that the model GPT-4.5 with 'included additional instructions on what kind of persona to adopt in responding to the interrogator' passed the test 73 percent of the time. This result ensures the relevance of ethical and privacy considerations in the context of using AI-based tools and systems.

### Key Ethical Challenges

Several issues can be observed as highlighted in recent studies, including data-induced and algorithmic bias, lack of transparency, privacy, and data protection rights, and questions of accountability. It is clear that using AI-based tools and systems in higher education should be done with caution and vigilance in accordance with the latest policies and guidelines.

#### Data-Induced and Algorithmic Bias

One of the sources of problems introduced by the increased use of AI-based tools and systems that use AI models built and trained on big amounts of data is the inherent bias in the data used to train the models. This bias can manifest in various ways, such as gender, race, or socioeconomic status bias. Such bias can lead to unfair outcomes and perpetuate existing inequalities. 

It is often that the data used to train AI models is not representative of the population it is intended to serve, leading to biased outcomes. Frequently, the average person will condone the output of an AI model and judge it is biased, while ignoring the fact that the perceived bias is based on the data the model was trained on. The bias that is shown by the model is, therefore, not the fault of the model itself, but the data it was trained on. The perceived bias is only perpetuating the bias in the data. Various examples of bias are documented in published studies, in the context of using AI-based tools and systems in higher education.

Ensuring fairness and non-biased results should be one of the fundamental features of using AI-based tools and systems. The goal is to prevent AI from hindering educational equity. Indeed, using AI should not be allowed to further deepen the digital divide or reinforce existing bias in the academia.

#### Lack of Transparency

Various AI models are observed using the black-box approach, i.e. the models are not transparent in their inner workings. In other words, nobody, not even the model authors, are completely aware of how some models work. This is especially true for complex machine learning models. This opacity, as we may describe the lack of transparency, can obscure, for example, why a student was flagged as at-risk by an AI-based system, or how and why an automated grading system suggests a particular score. 

Such opacity not only undermines trust but can also makes it difficult to challenge or appeal AI-driven decisions that affect student rights (such as admission or grading outcomes). The concept that fights for greater transparency in AI is called explainability. One of the identified key challenges of sustainable AI in education is 'ensuring ethics and transparency in data collection, use, and dissemination.' Increasing transparency might mean that, for example, students and staff are provided with clear information about what data an AI-based system uses, how those data are processed, and on what basis it reaches its outputs. It also means enabling explanations for individual decisions – for instance, explaining to a student why an intelligent tutoring system keeps recommending them a certain exercise.

The EU's AI Act introduces requirements for explainable AI, especially for high-stakes applications. High-risk AI systems (a category that includes many educational uses) are expected to provide interpretability so that their functioning can be understood and audited. Furthermore, data collection and use practices are regulated within the EU by the EU's General Data Protection Regulation (GDPR). The GDPR requires transparency in data collection and use, particularly when automated decision-making is involved. These regulations help make AI systems more transparent and comprehensible and boost accountability in using them.

#### Privacy and Data Protection

Although higher education might not be the most risk-prone domain of human activity, it relies on large amounts of data on students and employees, including academic records and learning management system logs. Storing data that may be classified as private or sensitive, including video recordings of lectures or students' personal background details and interaction with learning systems, raises significant privacy and data protection concerns. 

In order to enhance ethical use of data, the EU's GDPR directly addresses these concerns. It gives individuals enhanced rights and mandates increased transparency on how their data can be collected and processed. Under GDPR, data controllers (entities that collect data) such as universities, must inform users what will be done with their data before they are collected or processed and explain how their privacy is protected. In particular, Article 22 of the GDPR grants individuals the right not to be subject to decisions based solely on automated processing that may have significant effects, legal or otherwise, unless appropriate safeguard measures (like human review or intervention) are in place. This provision is highly relevant if, for example, a university were to use an AI model to make fully automated admissions decisions or degree grading.

Furthermore, the EU's AI Act controls how the collected data may be analysed and used, through the concepts of the right to privacy and to protection of personal data. These rights 'must be guaranteed throughout the entire lifecycle of the AI system.' Furthermore, in the context of processing personal data, the GDPR recognises several principles, such as data minimisation, purpose limitation, lawfulness, fairness, and transparency. Personal data is therein defined as 'any information relating to an identified or identifiable natural person.'

Within this context, universities and other higher education institutions must protect student and other personal data and obtain consent from students for the collection and use of their data in AI-based systems. This may be ensured by following the 'data protection by design and by default' concept mandated by the GDPR. Therefore, they uphold the privacy rights of the academic community, while leveraging data for educational benefits.

#### Bending Perception of Reality

The most recent advancement in artificial intelligence, especially generative artificial intelligence, which can be observed in some publicly available tools, services, and systems, allows the average person to bend the perception of reality. This poetic expression is used here to encompass all the activities that may influence others' perceptions of reality via exposure to fake content, manipulated information, or other means enabled or enhanced by AI. Models that made it possible to generate cute and innocent videos and photos can be used in more nefarious and malicious ways, such as fake reporting on natural disasters.

Therefore, it is obvious that AI-based tools and systems may be used to change students' and teachers' perceptions of the world. For example, AI-based tools and services may be used to generate fake student responses to assignments, fabricate sources with fake content, or manipulate images and videos to benefit either side or their loss.

## Towards Trustworthy AI in Education

The above discussion may be indicative of the considerations that must be taken into account with regard to the use of AI-based tools and systems in higher education. The concept that may be argued to encompass the above points is the concept of trustworthy AI. Such AI was described by the European Commission as a concept of three components: it should be lawful, ethical, and robust. In other words, trustworthy AI should be aligned with the applicable laws and regulations, respect and adhere to ethical principles and values, and be robust enough to prevent AI systems from causing unintentional harm.

Taking the above into consideration, the AI-HED project aims at aiding the responsible use of AI-based tools and systems in higher education. Better education, raised awareness, and improved ethical and privacy considerations in teachers and students are the main identified drivers of change in this context.

## AI-HED Resources

This project provides a solid starting point in considering the responsible use of AI-based tools and systems in higher education through various resources:

- A glossary of fundamental terms and phrases in the domain of artificial intelligence
- A collection of AI-based tools categorised into several descriptive categories and combined with a heatmap of tools and DigComp 2.2 competencies
- A collection of case studies that highlight the use of AI-based tools and systems in higher education
- A collection of current practice examples that highlight the use of AI-based tools and systems on the partner institutions of the project consortium

Visit our [resources section](https://ai-hed.eu/resources/) to explore these materials and learn more about integrating AI responsibly in higher education.
